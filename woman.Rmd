---
title: "woman in music"
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
    output: github_document
---

```{r setup, include=FALSE}

library(tidyverse)
library(tidymodels)
library(ggdendro)
library(protoclust)
library(plotly)
library(heatmaply)
library(spotifyr)
library(compmus)

```


Woman in music
-----------------------------------------------------------------------

### Presentation


My research is based on a principle of researching the playlists of the most listened to women in 2016,2017 and 2018. This would serve to determine which style of music could be the most listened to with female singers. 

Once analyzed the 3 lists we can say that the most listened to are: **Beyonc√©'s** *7/11* in 2016, **Selena Gomez**'s *Wolves* in 2017 and finally in 2018, the most listened to song was **Lady Gaga's** *Shallow* from the movie "a star has born", although this one is exactly in the same points as Ellie Goulding's Close To Me, and I chose Shallow because, in my opinion, it made much more impact than this second song. 

After having these three songs, I'd like to compare them so that I can see how the most listened to women of the last 3 years have evolved to see if they follow any pattern or if it's just a coincidence that these are the 3 most listened to. 


-----------------------------------------------------------------------

### Chromagrams

```{r chromagrams}{.sidebar}
wolves <- 
    get_tidy_audio_analysis('0tBbt8CrmxbjRP0pueQkyU') %>% 
    select(segments) %>% unnest(segments) %>% 
    select(start, duration, pitches)
beyonce <- 
    get_tidy_audio_analysis('02M6vucOvmRfMxTXDUwRXu') %>% 
    select(segments) %>% unnest(segments) %>% 
    select(start, duration, pitches)
shallow  <- 
    get_tidy_audio_analysis('2VxeLyX666F8uXCJ0dZF8B') %>% 
    select(segments) %>% unnest(segments) %>% 
    select(start, duration, pitches)

wolves %>% 
    mutate(pitches = map(pitches, compmus_normalise, 'euclidean')) %>% 
    compmus_gather_chroma %>% 
    ggplot(
        aes(
            x = start + duration / 2, 
            width = duration, 
            y = pitch_class, 
            fill = value)) + 
    geom_tile() +
    labs(x = 'Time (s)', y = NULL, fill = 'Magnitude') +
    theme_minimal()
beyonce %>% 
    mutate(pitches = map(pitches, compmus_normalise, 'euclidean')) %>% 
    compmus_gather_chroma %>% 
    ggplot(
        aes(
            x = start + duration / 2, 
            width = duration, 
            y = pitch_class, 
            fill = value)) + 
    geom_tile() +
    labs(x = 'Time (s)', y = NULL, fill = 'Magnitude') +
    theme_minimal()
shallow %>% 
    mutate(pitches = map(pitches, compmus_normalise, 'euclidean')) %>% 
    compmus_gather_chroma %>% 
    ggplot(
        aes(
            x = start + duration / 2, 
            width = duration, 
            y = pitch_class, 
            fill = value)) + 
    geom_tile() +
    labs(x = 'Time (s)', y = NULL, fill = 'Magnitude') +
    theme_minimal()



```

***
Here we can see the pitch graphics of Wolves, 7/11 and Shallow respectively. As we can see, the first and second have something in common, but the third already deviates from the other ones.  

### Cepstrogram

```{r}
wolvees <- 
    get_tidy_audio_analysis('0tBbt8CrmxbjRP0pueQkyU') %>% 
    compmus_align(bars, segments) %>% 
    select(bars) %>% unnest(bars) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'rms', norm = 'euclidean')) %>% 
    mutate(
        timbre = 
            map(segments, 
                compmus_summarise, timbre, 
                method = 'mean'))
beyoncee <- 
    get_tidy_audio_analysis('02M6vucOvmRfMxTXDUwRXu') %>% 
    compmus_align(bars, segments) %>% 
    select(bars) %>% unnest(bars) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'rms', norm = 'euclidean')) %>% 
    mutate(
        timbre = 
            map(segments, 
                compmus_summarise, timbre, 
                method = 'mean'))
shalloww <- 
    get_tidy_audio_analysis('2VxeLyX666F8uXCJ0dZF8B') %>% 
    compmus_align(bars, segments) %>% 
    select(bars) %>% unnest(bars) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'rms', norm = 'euclidean')) %>% 
    mutate(
        timbre = 
            map(segments, 
                compmus_summarise, timbre, 
                method = 'mean'))




wolvees %>%
    compmus_gather_timbre %>% 
    ggplot(
        aes(
            x = start + duration / 2, 
            width = duration, 
            y = basis, 
            fill = value)) + 
    geom_tile() +
    labs(x = 'Time (s)', y = NULL, fill = 'Magnitude') +
    scale_fill_viridis_c(option = 'E') +
    theme_classic()
beyoncee %>% 
    compmus_gather_timbre %>% 
    ggplot(
        aes(
            x = start + duration / 2, 
            width = duration, 
            y = basis, 
            fill = value)) + 
    geom_tile() +
    labs(x = 'Time (s)', y = NULL, fill = 'Magnitude') +
    scale_fill_viridis_c(option = 'E') +
    theme_classic()
shalloww %>% 
    compmus_gather_timbre %>% 
    ggplot(
        aes(
            x = start + duration / 2, 
            width = duration, 
            y = basis, 
            fill = value)) + 
    geom_tile() +
    labs(x = 'Time (s)', y = NULL, fill = 'Magnitude') +
    scale_fill_viridis_c(option = 'E') +
    theme_classic()

```


*** 
observing now the ceptograms, we can observe that again, the songs of 2016- 2017 have some similarity, but that nevertheless the 2018 returns to break with the norm that they are similar. 

### comparation 

```{r}

wolvees %>% 
    compmus_self_similarity(timbre, 'cosine') %>% 
    ggplot(
        aes(
            x = xstart + xduration / 2, 
            width = xduration,
            y = ystart + yduration / 2,
            height = yduration,
            fill = d)) + 
    geom_tile() +
    coord_fixed() +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    theme_classic() +
    labs(x = '', y = '') 
beyoncee %>% 
    compmus_self_similarity(timbre, 'cosine') %>% 
    ggplot(
        aes(
            x = xstart + xduration / 2, 
            width = xduration,
            y = ystart + yduration / 2,
            height = yduration,
            fill = d)) + 
    geom_tile() +
    coord_fixed() +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    theme_classic() +
    labs(x = '', y = '')
shalloww %>% 
    compmus_self_similarity(timbre, 'cosine') %>% 
    ggplot(
        aes(
            x = xstart + xduration / 2, 
            width = xduration,
            y = ystart + yduration / 2,
            height = yduration,
            fill = d)) + 
    geom_tile() +
    coord_fixed() +
    scale_fill_viridis_c(option = 'E', guide = 'none') +
    theme_classic() +
    labs(x = '', y = '')


```

***
However, we see that with respect to the structure of this analysis, Shallow looks more like Wolves than 7/11



### Comparation 
```{r}
woman2016 <-
    get_playlist_audio_features(
        'spotify', 
        '37i9dQZF1DX82tVoNhkbcO') %>% 
    slice(1:30) %>% 
    add_audio_analysis()
woman2017 <-
    get_playlist_audio_features(
        'spotify', 
        '37i9dQZF1DX27hx1vGd0BZ') %>% 
    slice(1:30) %>% 
    add_audio_analysis()
woman2018 <-
    get_playlist_audio_features(
        'spotify', 
        '37i9dQZF1DX82tVoNhkbcO') %>% 
    slice(1:30) %>% 
    add_audio_analysis()

womanunoydos <-
    woman2016 %>% mutate(genre = "Year 2016") %>%
    bind_rows(woman2017 %>% mutate(genre = "Year 2017"))
womandosytres <-
    woman2017 %>% mutate(genre = "Year 2017") %>%
    bind_rows(woman2018 %>% mutate(genre = "Year 2018"))
womanunoytres <-
    woman2017 %>% mutate(genre = "Year 2016") %>%
    bind_rows(woman2018 %>% mutate(genre = "Year 2018"))


womanunoytres %>% 
    mutate(
        sections = 
            map(
                sections, 
                summarise_at, 
                vars(tempo, loudness, duration), 
                list(section_mean = mean, section_sd = sd))) %>% 
    unnest(sections) %>%
    ggplot(
        aes(
            x = tempo, 
            y = tempo_section_sd, 
            colour = genre, 
            alpha = loudness)) +
    geom_point(aes(size = duration / 60)) + 
    geom_rug() + 
    theme_minimal() +
    ylim(0, 5) + 
    labs(
        x = 'Mean Tempo (bpm)', 
        y = 'SD Tempo', 
        colour = 'Genre', 
        size = 'Duration (min)', 
        alpha = 'Volume (dBFS)')

womandosytres %>% 
    mutate(
        sections = 
            map(
                sections, 
                summarise_at, 
                vars(tempo, loudness, duration), 
                list(section_mean = mean, section_sd = sd))) %>% 
    unnest(sections) %>%
    ggplot(
        aes(
            x = tempo, 
            y = tempo_section_sd, 
            colour = genre, 
            alpha = loudness)) +
    geom_point(aes(size = duration / 60)) + 
    geom_rug() + 
    theme_minimal() +
    ylim(0, 5) + 
    labs(
        x = 'Mean Tempo (bpm)', 
        y = 'SD Tempo', 
        colour = 'Genre', 
        size = 'Duration (min)', 
        alpha = 'Volume (dBFS)')
        
        


```

*** 
Finally, here we can find what would be the coincidences between the years in numerical values, we are no longer talking about the number one, as we have spoken before, but we have included each and every one of the songs that enter the top of most listened songs that are sung by women. How many songs are similar after each year? Here we can see it. 



###Comparation

```{r}



woman2016 <-
    get_playlist_audio_features(
        'spotify', 
        '37i9dQZF1DX82tVoNhkbcO') %>% 
    slice(1:30) %>% 
    add_audio_analysis()
woman2017 <-
    get_playlist_audio_features(
        'spotify', 
        '37i9dQZF1DX27hx1vGd0BZ') %>% 
    slice(1:30) %>% 
    add_audio_analysis()
woman2018 <-
    get_playlist_audio_features(
        'spotify', 
        '37i9dQZF1DX82tVoNhkbcO') %>% 
    slice(1:30) %>% 
    add_audio_analysis()

wowoman <- 
    woman2016 %>% mutate(playlist = "Year 2016") %>% 
    bind_rows(
        woman2017 %>% mutate(playlist = "Year 2017"),
        woman2018 %>% mutate(playlist = "Year 2018")) %>% 
    mutate(playlist = factor(playlist)) %>% 
    mutate(
        segments = 
            map2(segments, key, compmus_c_transpose)) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'mean', norm = 'manhattan'),
        timbre =
            map(
                segments,
                compmus_summarise, timbre,
                method = 'mean')) %>% 
    mutate(pitches = map(pitches, compmus_normalise, 'clr')) %>% 
    mutate_at(vars(pitches, timbre), map, bind_rows) %>% 
    unnest(pitches, timbre)

wowoman_class <- 
    recipe(playlist ~
               danceability +
               energy +
               loudness +
               speechiness +
               acousticness +
               instrumentalness +
               liveness +
               valence +
               tempo +
               duration_ms +
               C + `C#|Db` + D + `D#|Eb` +
               E + `F` + `F#|Gb` + G +
               `G#|Ab` + A + `A#|Bb` + B +
               c01 + c02 + c03 + c04 + c05 + c06 +
               c07 + c08 + c09 + c10 + c11 + c12,
           data = wowoman) %>% 
    step_center(all_predictors()) %>%
    step_scale(all_predictors()) %>%
    # step_range(all_predictors()) %>% 
    prep(wowoman) %>% 
    juice

wowoman_cv <- wowoman_class %>% vfold_cv(5)

wowoman_knn <- nearest_neighbor(neighbors = 1) %>% set_engine('kknn')

predict_knn <- function(split)
    fit(wowoman_knn, playlist ~ ., data = analysis(split)) %>% 
    predict(assessment(split), type = 'class') %>%
    bind_cols(assessment(split))
    
    
wowoman_cv %>% 
    mutate(pred = map(splits, predict_knn)) %>% unnest(pred) %>% 
    conf_mat(truth = playlist, estimate = .pred_class) %>% 
    autoplot(type = 'heatmap')
    
```


***
Here we can see a list of coincidences that could be found between the 2016, 2017, and 2018 lists. 




###Dendrogram 

```{r}

top3woman <- 
    get_playlist_audio_features('21lvahlac7sbowf4rk5wedszi','5arkYz4W5msKrKu9mwkg2x') %>% 
    add_audio_analysis %>% 
    mutate(
        segments = 
            map2(segments, key, compmus_c_transpose)) %>% 
    mutate(
        segments =
            map(
                segments,
                mutate,
                delta_timbre = map2(timbre, lag(timbre), `-`))) %>% 
    mutate(
        pitches = 
            map(segments, 
                compmus_summarise, pitches, 
                method = 'mean', norm = 'manhattan'),
        timbre =
            map(
                segments,
                compmus_summarise, timbre,
                method = 'mean'),
        delta_timbre =
            map(
                segments,
                compmus_summarise, delta_timbre,
                method = 'mean')) %>% 
    mutate(pitches = map(pitches, compmus_normalise, 'clr')) %>% 
    mutate_at(vars(pitches, timbre, delta_timbre), map, bind_rows) %>% 
    unnest(pitches, timbre, delta_timbre)
  
  
top3woman_juice <- 
    recipe(track_name ~
               danceability +
               energy +
               loudness +
               speechiness +
               acousticness +
               instrumentalness +
               liveness +
               valence +
               tempo +
               duration_ms +
               C + `C#|Db` + D + `D#|Eb` +
               E + `F` + `F#|Gb` + G +
               `G#|Ab` + A + `A#|Bb` + B +
               c01 + c02 + c03 + c04 + c05 + c06 +
               c07 + c08 + c09 + c10 + c11 + c12,
           data = top3woman) %>% 
    step_center(all_predictors()) %>%
    step_scale(all_predictors()) %>%
    prep(top3woman %>% mutate(track_name = str_trunc(track_name, 20))) %>% 
    juice %>% 
    column_to_rownames('track_name')
woman3_dist <- dist(top3woman_juice, method = 'euclidean')
hclust(woman3_dist, method = 'single') %>% dendro_data %>% ggdendrogram



```

***
Here I decided to use the analysis to finally know if there is any pattern between the top 3 songs of each year. Could we get to some classification? 





### Conclusion 

 We can conclude, with all this exposed I can get to say that although the songs have some resemblance in some aspect (the top of each year), never get to establish a pattern that is visible to create a success, will there be a formula for it? However, as an observation, we can see that when we compare the entire lists there is some similarity between them, so maybe "in general features" we can create a "success" by listening to the songs that were successful in recent years. 
